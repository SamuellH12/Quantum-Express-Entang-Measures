{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c38ee41",
   "metadata": {},
   "source": [
    "# Getting Datasets\n",
    "Datasets from https://github.com/BrunoMog/Pibic-Quantum-Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78d85f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blobs_2classes_16features_500samples_low_noise', 'blobs_2classes_16features_500samples_no_noise', 'blobs_2classes_16features_50samples_low_noise', 'blobs_2classes_16features_50samples_no_noise', 'blobs_2classes_2features_500samples_low_noise', 'blobs_2classes_2features_500samples_no_noise', 'blobs_2classes_2features_50samples_low_noise', 'blobs_2classes_2features_50samples_no_noise', 'blobs_2classes_4features_500samples_low_noise', 'blobs_2classes_4features_500samples_no_noise', 'blobs_2classes_4features_50samples_low_noise', 'blobs_2classes_4features_50samples_no_noise', 'blobs_2classes_8features_500samples_low_noise', 'blobs_2classes_8features_500samples_no_noise', 'blobs_2classes_8features_50samples_low_noise', 'blobs_2classes_8features_50samples_no_noise', 'blobs_3classes_16features_500samples_low_noise', 'blobs_3classes_16features_500samples_no_noise', 'blobs_3classes_16features_50samples_low_noise', 'blobs_3classes_16features_50samples_no_noise', 'blobs_3classes_2features_500samples_low_noise', 'blobs_3classes_2features_500samples_no_noise', 'blobs_3classes_2features_50samples_low_noise', 'blobs_3classes_2features_50samples_no_noise', 'blobs_3classes_4features_500samples_low_noise', 'blobs_3classes_4features_500samples_no_noise', 'blobs_3classes_4features_50samples_low_noise', 'blobs_3classes_4features_50samples_no_noise', 'blobs_3classes_8features_500samples_low_noise', 'blobs_3classes_8features_500samples_no_noise', 'blobs_3classes_8features_50samples_low_noise', 'blobs_3classes_8features_50samples_no_noise', 'blobs_4classes_16features_500samples_low_noise', 'blobs_4classes_16features_500samples_no_noise', 'blobs_4classes_16features_50samples_low_noise', 'blobs_4classes_16features_50samples_no_noise', 'blobs_4classes_2features_500samples_low_noise', 'blobs_4classes_2features_500samples_no_noise', 'blobs_4classes_2features_50samples_low_noise', 'blobs_4classes_2features_50samples_no_noise', 'blobs_4classes_4features_500samples_low_noise', 'blobs_4classes_4features_500samples_no_noise', 'blobs_4classes_4features_50samples_low_noise', 'blobs_4classes_4features_50samples_no_noise', 'blobs_4classes_8features_500samples_low_noise', 'blobs_4classes_8features_500samples_no_noise', 'blobs_4classes_8features_50samples_low_noise', 'blobs_4classes_8features_50samples_no_noise', 'circles_500samples_low_noise', 'circles_500samples_no_noise', 'circles_50samples_low_noise', 'circles_50samples_no_noise', 'moons_500samples_low_noise', 'moons_500samples_no_noise', 'moons_50samples_low_noise', 'moons_50samples_no_noise', 'xor_500samples_low_noise', 'xor_500samples_no_noise', 'xor_50samples_low_noise', 'xor_50samples_no_noise']\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from local.listDatabases import get_csv_path_list, get_pkl_path_list, get_dataframes_and_samples\n",
    "import pickle\n",
    "\n",
    "DATASETS = get_dataframes_and_samples('./local')\n",
    "NEW_DATASET = {}\n",
    "\n",
    "for dt_name in DATASETS:\n",
    "    if 'high_noise' not in dt_name:\n",
    "        NEW_DATASET[dt_name] = DATASETS[dt_name]\n",
    "\n",
    "DATASETS = NEW_DATASET\n",
    "\n",
    "print(list(DATASETS.keys()))\n",
    "print(len(DATASETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced6d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[426 917  84 852 968 931 213 703 998 614 338  48 232 759  96 914  23 485\n",
      " 428 413 727 895 702 844 886 107 355 869 401 699 219 267 118  47 740 430\n",
      " 855 650 304 228 970 554 195 290 745 964 336 615 559 487 847 421 503 447\n",
      " 974 455 919 996 540 536  93 125 979 957 763  32 164 751 162 306 509 551\n",
      " 716 523  44 479 320 275 286 905 532 773 651 143 152 307 557 122 175 947\n",
      " 738 414 266 861 325 261 368 117 802 294]\n",
      "700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: target, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe com os dados\n",
    "print(len(DATASETS['blobs_2classes_2features_500samples_low_noise']['samples']))\n",
    "print(DATASETS['blobs_2classes_2features_500samples_low_noise']['samples'][0][:100])\n",
    "print(len(DATASETS['blobs_2classes_2features_500samples_low_noise']['samples'][0]))\n",
    "DATASETS['blobs_2classes_2features_500samples_low_noise']['df']['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8cf191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16, 2), (16, 3), (16, 4)]\n",
      "[(2, 2), (2, 3), (2, 4)]\n",
      "[(4, 2), (4, 3), (4, 4)]\n",
      "[(8, 2), (8, 3), (8, 4)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['blobs_2classes_2features_500samples_low_noise',\n",
       " 'blobs_2classes_2features_500samples_no_noise',\n",
       " 'blobs_2classes_2features_50samples_low_noise',\n",
       " 'blobs_2classes_2features_50samples_no_noise',\n",
       " 'circles_500samples_low_noise',\n",
       " 'circles_500samples_no_noise',\n",
       " 'circles_50samples_low_noise',\n",
       " 'circles_50samples_no_noise',\n",
       " 'moons_500samples_low_noise',\n",
       " 'moons_500samples_no_noise',\n",
       " 'moons_50samples_low_noise',\n",
       " 'moons_50samples_no_noise',\n",
       " 'xor_500samples_low_noise',\n",
       " 'xor_500samples_no_noise',\n",
       " 'xor_50samples_low_noise',\n",
       " 'xor_50samples_no_noise']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organizar o dataset pela quantidade de features e classes\n",
    "DATASET_BY_FEATURES = {}\n",
    "\n",
    "for name, data in DATASETS.items():\n",
    "\n",
    "    num_features = len(data['df'].columns) - 1\n",
    "    num_classes = len(set(data['df']['target']))\n",
    "    \n",
    "    if num_features not in DATASET_BY_FEATURES: DATASET_BY_FEATURES[num_features] = {}\n",
    "    if num_classes not in DATASET_BY_FEATURES[num_features]: DATASET_BY_FEATURES[num_features][num_classes] = {}\n",
    "    \n",
    "    DATASET_BY_FEATURES[num_features][num_classes][name] = data\n",
    "\n",
    "[print([(feat, classes) for classes in DATASET_BY_FEATURES[feat].keys() ]) for feat in DATASET_BY_FEATURES.keys() ]\n",
    "list(DATASET_BY_FEATURES[2][2].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b6d6d",
   "metadata": {},
   "source": [
    "# Getting Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b486b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "6 ['hr', 'ru', 'ruu', 'rx', 'ry', 'rz']\n",
      "5 ['alpha', 'beta', 'gamma', 'phi', 'theta']\n",
      "10 ['0_zero', '1_mochi', '2_yadi', '3_tatu', '4_wana', '5_tano', '6_samanu', '7_sambwadi', '8_nake', '9_divwe']\n",
      "15 ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from circuits.listCircuits import get_circuit_path_list\n",
    "from circuits.pennylaneCircuitParse import get_pennylane_circuit_from_file\n",
    "PATH = 'circuits/CostaSH'\n",
    "\n",
    "# Circuit list by number of qubits\n",
    "CIRCUITS = [[]]\n",
    "\n",
    "CIRCUITS.append([])\n",
    "for path in get_circuit_path_list(PATH + '/1qubit'):\n",
    "    name = path.split('/')[-1].split('.')[0]\n",
    "    circuit, dev, nparams = get_pennylane_circuit_from_file(path)\n",
    "    CIRCUITS[1].append( {'name':name, 'circuit' : circuit, 'dev' : dev, 'nparams' : nparams, 'path':path} )\n",
    "\n",
    "for i in range(2, 5):\n",
    "    CIRCUITS.append([])\n",
    "    for path in get_circuit_path_list(PATH + f'/{i}qubits'):\n",
    "        name = path.split('/')[-1].split('.')[0]\n",
    "        circuit, dev, nparams = get_pennylane_circuit_from_file(path, {'&L' : 1})\n",
    "        CIRCUITS[i].append( {'name':name, 'circuit' : circuit, 'dev' : dev, 'nparams' : nparams, 'path':path} )\n",
    "\n",
    "[print(len(Nqubits), [circuit['name'] for circuit in Nqubits]) for  Nqubits in CIRCUITS ]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d92b8b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d71324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.optimize import NesterovMomentumOptimizer, GradientDescentOptimizer, SPSAOptimizer\n",
    "from qmlHelper.metrics import square_loss_silhouette, square_loss_calinski_harabasz_score, square_loss_davies_bouldin_score\n",
    "\n",
    "EMBEDDING = ['phasex', \n",
    "            #  'phasey', \n",
    "             'amplitude']\n",
    "### (optimizer, opt_params)\n",
    "OPTIMIZERS = {\n",
    "              'SPSAOptimizer(10)' : (SPSAOptimizer, [10]),\n",
    "              # 'GradientDescentOptimizer(1)' : (GradientDescentOptimizer, [1]), \n",
    "            #   'NesterovMomentumOptimizer(0.1)' :(NesterovMomentumOptimizer, [0.1]),  \n",
    "              } \n",
    "METRICS = {'silhouette' : square_loss_silhouette, \n",
    "           'calinski harabasz' : square_loss_calinski_harabasz_score,\n",
    "          #  'davies bouldin' : square_loss_davies_bouldin_score\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74237abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from qmlHelper.utils import train_ansatz, cost\n",
    "from qmlHelper.metrics import unsupervised_accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 157\n",
    "BATCH_SIZE = 1\n",
    "STEPS = 0\n",
    "CIRCUIT_ARGS = {'encoding': 'phase',\n",
    "                'meas': 'expval',\n",
    "                'measwire': [0],\n",
    "                'run_quiet': True}\n",
    "\n",
    "\n",
    "def run_one_task(use_bias, qubits, circuit_path, circuit_name, nparams, n_feat, n_classes, \n",
    "                  df_name, sample_index, dataset,\n",
    "                  encoding, opt_name, optimizer, opt_params, \n",
    "                  metrc_name, metric, wires_to_measure, measure_type ):\n",
    "    \n",
    "    circuit, dev, nparams = get_pennylane_circuit_from_file(circuit_path, {'&L' : 1})\n",
    "\n",
    "    circuit_args = CIRCUIT_ARGS\n",
    "    circuit_args['encoding'] = encoding\n",
    "    circuit_args['meas'] = measure_type\n",
    "    circuit_args['measwire'] = range(wires_to_measure)\n",
    "\n",
    "    data = dataset.drop(columns=['target'], inplace=False).to_numpy()\n",
    "    labels = dataset['target'].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split( data, labels, test_size=0.3, random_state=SEED, stratify=labels )\n",
    "    \n",
    "    try:\n",
    "        weights, bias = train_ansatz(circuit  = circuit,\n",
    "                                    n_params = nparams, \n",
    "                                    circuit_args = circuit_args, \n",
    "                                    data = X_train, \n",
    "                                    labels = y_train, \n",
    "                                    batch_size = BATCH_SIZE, \n",
    "                                    Steps = STEPS, \n",
    "                                    cost_metric = metric, \n",
    "                                    opt = optimizer(*opt_params),\n",
    "                                    seed=SEED, \n",
    "                                    threshold_n_classes = n_classes, \n",
    "                                    use_bias = use_bias\n",
    "                                    )   \n",
    "                                                \n",
    "        entry = {'ARQUITETURA_ANSATZ' :  circuit,\n",
    "                'INPUT_EMBEDDING': encoding,\n",
    "                'DATASET': df_name,\n",
    "                'DATASET_DIVISION_INDEX': sample_index,\n",
    "                'OPTIMIZER': opt_name,\n",
    "                'UNSUPERVISED_METRIC': metrc_name,\n",
    "                'MEASURED_WIRES': wires_to_measure,\n",
    "                'MEASURE_TYPE': measure_type,\n",
    "                'TRAIN_METRIC_COST': cost(circuit, weights, bias, metric, X_train, y_train, n_classes, circuit_args),\n",
    "                'TEST_METRIC_COST':  cost(circuit, weights, bias, metric, X_test,  y_test,  n_classes, circuit_args),\n",
    "                'TRAIN_ACCURACY': unsupervised_accuracy(circuit, weights, bias, X_train, y_train, n_classes, circuit_args),\n",
    "                'TEST_ACCURACY': unsupervised_accuracy(circuit, weights, bias, X_test, y_test, n_classes, circuit_args),\n",
    "                'WEIGHT': weights,\n",
    "                'BIAS': bias,\n",
    "                'USE_BIAS': 'YES' if use_bias else 'NO',\n",
    "        }\n",
    "\n",
    "        return entry\n",
    "\n",
    "    except Exception as e:\n",
    "        entry_id = {'ARQUITETURA_ANSATZ' :  circuit_name, 'INPUT_EMBEDDING': encoding, 'DATASET': df_name, 'DATASET_DIVISION_INDEX': sample_index, 'OPTIMIZER': opt_name, 'UNSUPERVISED_METRIC': metrc_name, 'MEASURED_WIRES': wires_to_measure, 'MEASURE_TYPE': measure_type}\n",
    "        print('Error at:', entry_id)\n",
    "        print(f\"Error: {str(e)}\\nTraceback:\\n{traceback.format_exc()}\")\n",
    "        return entry_id\n",
    "\n",
    "def run_one_task_args(args):\n",
    "    try:\n",
    "        return run_one_task(*args)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b36074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28080\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 10\n",
    "TASKS = []\n",
    "\n",
    "for use_bias in [True]:\n",
    "    for qubits in range(1, 5):\n",
    "        for circuit in CIRCUITS[qubits]:\n",
    "\n",
    "            for n_feat, datasets_by_class in DATASET_BY_FEATURES.items():\n",
    "                for n_classes, datasets_by_name in datasets_by_class.items():\n",
    "                    for df_name, dataset in datasets_by_name.items():\n",
    "                        for encoding in EMBEDDING:\n",
    "                            if encoding == 'amplitude' and n_feat != 2**qubits: continue # 2^N features to N qubits\n",
    "                            if encoding.startswith('phase') and n_feat > qubits: continue # não há qubits suficientes para carregar os dados                \n",
    "                            for sample_index, sample in zip(range(MAX_SAMPLES), dataset['samples']):    \n",
    "                                for opt_name, (optimizer, opt_params) in OPTIMIZERS.items():\n",
    "                                    for metrc_name, metric in METRICS.items():\n",
    "                                        # ENTRY_GROUP = []\n",
    "                                        # print({'ARQUITETURA_ANSATZ' :  circuit['name'], 'INPUT_EMBEDDING': encoding, 'DATASET': df_name})\n",
    "                                        for wires_to_measure in [1]: #, n_classes]:\n",
    "                                            for measure_type in ['expval']: # + 'probs' ?\n",
    "                                                if wires_to_measure > qubits: continue\n",
    "                                                \n",
    "                                                TASKS.append((use_bias, qubits, circuit['path'], circuit['name'], circuit['nparams'], n_feat, n_classes, \n",
    "                                                              df_name, sample_index, dataset['df'].loc[sample], \n",
    "                                                              encoding, opt_name, optimizer, opt_params, \n",
    "                                                              metrc_name, metric, wires_to_measure, measure_type ))\n",
    "\n",
    "                                                # ENTRY_GROUP.append(run_one_task(*TASKS[-1]))\n",
    "                                        ### END OF for wires to measure\n",
    "                                        # save_dataframe(pd.DataFrame(ENTRY_GROUP), FILENAME)\n",
    "                                ### END OF for optimizer\n",
    "                            ## END OF for samples\n",
    "\n",
    "print(len(TASKS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d381776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenProcessPool\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m                     results.append(future.result())\n\u001b[32m     18\u001b[39m                     pbar.update(\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m final_df = pd.DataFrame(\u001b[43mrun_task_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTASKS\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     21\u001b[39m save_dataframe(final_df, FILENAME)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mrun_task_parallel\u001b[39m\u001b[34m(tasks)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks: futures.append(executor.submit(run_one_task_args, task))\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent.futures.as_completed(futures):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     results.append(\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     18\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mBrokenProcessPool\u001b[39m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "from local.listDatabases import save_dataframe\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "MAX_WORKERS = max(os.cpu_count() - 1, 1)\n",
    "\n",
    "FILENAME = 'reports_data/Ansatz_reduced_training_reports(CostaSH).csv'\n",
    "\n",
    "def run_task_parallel(tasks):\n",
    "        results = []\n",
    "        with tqdm(total=len(tasks)) as pbar:\n",
    "            with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "                futures = []\n",
    "                for task in tasks: futures.append(executor.submit(run_one_task_args, task))\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    results.append(future.result())\n",
    "                    pbar.update(1)\n",
    "\n",
    "final_df = pd.DataFrame(run_task_parallel(TASKS[:4]))\n",
    "save_dataframe(final_df, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe3c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.49s/it]\n"
     ]
    }
   ],
   "source": [
    "result = [run_one_task_args(task) for task in tqdm(TASKS[:4])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
